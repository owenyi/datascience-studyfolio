{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST NN 은닉 계층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3계층의 신경망으로 MNIST 데이터를 학습하는 코드\n",
    "\n",
    "import numpy as np\n",
    "# 시그모이드 함수 expit() 사용을 위해 scipy.special 불러오기\n",
    "from scipy.special import expit\n",
    "# 행렬을 시각화하기 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "# 외부 윈도우가 아닌 현재에 노트북 내에서 시각화되도록 설정\n",
    "activ_fct = lambda x: expit(x)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 클래스 정의\n",
    "class neuralNetwork:\n",
    "\n",
    "    # 신경망 초기화\n",
    "    def __init__(self, inodes, hnodes, onodes, lr):\n",
    "        # 입력, 은닉, 출력 계층의 노드 개수 설정\n",
    "        # NNlab1에서는 333, 222를 다뤘지만 각 계층의 노드 수가 다를 수도 있음\n",
    "        self.inodes = inodes\n",
    "        self.hnodes = hnodes\n",
    "        self.onodes = onodes\n",
    "\n",
    "        # 가중치 행렬, 행렬은 대문자로 표기\n",
    "        # 배열 내 가중치는 w_ij로 표기, 노드 i에서 다음 계층의 노드 j로 연결됨\n",
    "        self.W_ih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.W_ho = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # 학습률\n",
    "        self.lr = lr\n",
    "\n",
    "        # 활성화 함수로는 시그모이드 함수를 이용\n",
    "        self.activ_fct = lambda x: expit(x)\n",
    "        pass\n",
    "\n",
    "    # 신경망 학습시키기\n",
    "    def train(self, input_list, target_list):\n",
    "        # 리스트(1 x n) -> 넘파이 행렬(n x 1)\n",
    "        I_i = np.array(input_list, ndmin=2).T\n",
    "        T_o = np.array(target_list, ndmin=2).T\n",
    "\n",
    "        # 은닉 계층으로 들어오는 신호\n",
    "        I_h = np.dot(self.W_ih, I_i) # (주의)입력 계층에서는 I를 사용\n",
    "        # 은닉 계층에서 나가는 신호\n",
    "        O_h = self.activ_fct(I_h)\n",
    "\n",
    "        # 출력 계층으로 들어오는 신호\n",
    "        I_o = np.dot(self.W_ho, O_h) # 그 외 계층에서는 O를 사용\n",
    "        # 출력 계층에서 나가는 신호\n",
    "        O_o = self.activ_fct(I_o)\n",
    "\n",
    "        # 출력 계층의 오차는 (실제 값 - 계산 값)\n",
    "        E_o = T_o - O_o\n",
    "        # 은닉 계층의 오차는\n",
    "        E_h = np.dot(self.W_ho.T, E_o)\n",
    "\n",
    "        # 은닉 계층과 출력 계층 간의 가중치 업데이트 (W = W - lr * dE/dW, dE/dW = - (t - o) * ...)\n",
    "        self.W_ho += self.lr * np.dot(E_o * O_o * (1.0 - O_o), O_h.T)\n",
    "\n",
    "        # 입력 계층과 은닉 계층 간의 가중치 업데이트\n",
    "        self.W_ih += self.lr * np.dot(E_h * O_h * (1 - O_h), I_i.T)\n",
    "        pass\n",
    "\n",
    "    # 신경망에 질의하기\n",
    "    def query(self, input_list):\n",
    "        # 리스트(1 x n) -> 넘파이 행렬(n x 1)\n",
    "        I_i = np.array(input_list, ndmin=2).T\n",
    "\n",
    "        # 은닉 계층으로 들어오는 신호\n",
    "        I_h = np.dot(self.W_ih, I_i)\n",
    "        # 은닉 계층에서 나가는 신호\n",
    "        O_h = self.activ_fct(I_h)\n",
    "\n",
    "        # 출력 계층으로 들어오는 신호\n",
    "        I_o = np.dot(self.W_ho, O_h)\n",
    "        # 출력 계층에서 나가는 신호\n",
    "        O_o = self.activ_fct(I_o)\n",
    "\n",
    "        return O_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력, 은닉, 출력 노드의 수\n",
    "inodes = 784\n",
    "hnodes = 200\n",
    "onodes = 10\n",
    "\n",
    "# 학습률\n",
    "lr = 0.1\n",
    "\n",
    "# 신경망의 인스턴스 생성\n",
    "n = neuralNetwork(inodes, hnodes, onodes, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist 학습 데이터 불러오기\n",
    "train_data_file = open(\"../mnist_dataset/mnist_train.csv\", \"r\")\n",
    "train_data_list = train_data_file.readlines()\n",
    "train_data_file.close()\n",
    "\n",
    "len(train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 done\n",
      "epoch 1 done\n",
      "epoch 2 done\n",
      "epoch 3 done\n",
      "epoch 4 done\n"
     ]
    }
   ],
   "source": [
    "# 신경망 학습시키기\n",
    "\n",
    "# 주기(epoch)란 학습 데이터가 학습을 위해 사용되는 횟수를 의미\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"epoch {i}\", end=\" \")\n",
    "    # 학습 데이터의 레코드를 순서대로 방문\n",
    "    for record in train_data_list:\n",
    "        # 레코드를 쉼표로 split\n",
    "        all_values = record.split(',')\n",
    "        # 입력 값의 범위와 값 조정\n",
    "        inputs = np.asfarray(all_values[1:]) / 255.0 * 0.99 + 0.01\n",
    "        # 결과 값 생성 (실제 값인 0.99 외에는 모두 0.01)\n",
    "        targets = np.zeros(onodes) + 0.1\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "\n",
    "        # 학습\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    print(\"done\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist 학습 데이터 불러오기\n",
    "test_data_file = open(\"../mnist_dataset/mnist_test.csv\", \"r\")\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "len(test_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 테스트\n",
    "\n",
    "# 신경망 성능의 지표가 되는 성적표를 아무 값도 가지지 않도록 초기화\n",
    "scorecard = []\n",
    "\n",
    "# 테스트 데이터의 레코드를 순서대로 방문\n",
    "for record in test_data_list:\n",
    "    # 레코드를 쉼표로 split\n",
    "    all_values = record.split(',')\n",
    "    # 정답은 index 0의 값\n",
    "    correct_label = int(all_values[0])\n",
    "    # 입력 값의 범위와 값 조정\n",
    "    inputs = np.asfarray(all_values[1:]) / 255.0 * 0.99 + 0.01\n",
    "    # 신경망에 질의\n",
    "    outputs = n.query(inputs)\n",
    "    # 가장 높은 값의 인덱스는 레이블의 인덱스와 일치\n",
    "    label = np.argmax(outputs)\n",
    "    # 정답 또는 오답을 리스트에 추가\n",
    "    if (label == correct_label): # 정답이면\n",
    "        scorecard.append(1) # 성적표에 1을 추가\n",
    "    else: # 오답이면\n",
    "        scorecard.append(0) # 성적표에 0을 추가\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hnodes = 200 lr = 0.1 epochs = 5 performance = 0.956\n"
     ]
    }
   ],
   "source": [
    "# 정답의 비율인 성적을 계산해 출력\n",
    "scorecard_array = np.asfarray(scorecard)\n",
    "print(f\"hnodes = {hnodes} lr = {lr} epochs = {epochs} performance = {scorecard_array.sum() / scorecard_array.size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
